{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "93a10a92",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello world\n"
          ]
        }
      ],
      "source": [
        "print(\"hello world\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "id": "f4fd9326",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "id": "c538beed",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "48128a81",
      "metadata": {},
      "outputs": [],
      "source": [
        "gemini_api_key = os.getenv(\"gemini_api_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be830c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not gemini_api_key:\n",
        "    raise ValueError(\"No Gemini API key found. Please set the GEMINI_API_KEY environment variable.\")\n",
        "\n",
        "chat_llm = ChatGoogleGenerativeAI(model=\"gemini-3-flash-preview\", google_api_key=gemini_api_key)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "id": "d2bbb53b",
      "metadata": {},
      "outputs": [
        {
          "ename": "ChatGoogleGenerativeAIError",
          "evalue": "Error calling model 'gemini-3-flash' (INVALID_ARGUMENT): 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key expired. Please renew the API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key expired. Please renew the API key.'}]}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:3047\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/google/genai/models.py:5621\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5620\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5621\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5623\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5625\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/google/genai/models.py:4283\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4281\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4283\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4284\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4288\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4289\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/google/genai/_api_client.py:1396\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1393\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1394\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1395\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1397\u001b[39m response_body = (\n\u001b[32m   1398\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1399\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/google/genai/_api_client.py:1230\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1229\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/tenacity/__init__.py:470\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/tenacity/__init__.py:371\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/tenacity/__init__.py:393\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/tenacity/__init__.py:473\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/google/genai/_api_client.py:1209\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1202\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1203\u001b[39m     method=http_request.method,\n\u001b[32m   1204\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1207\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1208\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1211\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1212\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/google/genai/errors.py:134\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    132\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/google/genai/errors.py:159\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
            "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key expired. Please renew the API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key expired. Please renew the API key.'}]}}",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[197]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchat_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:2535\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2532\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2533\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:3051\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3048\u001b[39m         **request,\n\u001b[32m   3049\u001b[39m     )\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3051\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LangAgents/env/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
            "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-3-flash' (INVALID_ARGUMENT): 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key expired. Please renew the API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key expired. Please renew the API key.'}]}}"
          ]
        }
      ],
      "source": [
        "chat_llm.invoke(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "b680f9cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict, Annotated\n",
        "import operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "db16028a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "094b2938",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "0dabbc20",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hi']"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[\"hi\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "c388945b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hi', 'how are you']"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[\"hi\", \"how are you\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "fdbbae67",
      "metadata": {},
      "outputs": [],
      "source": [
        "def llm_call(state: GraphState) -> dict:\n",
        "    \"\"\"Call the LLM using conversation messages and append AI response.\"\"\"\n",
        "    response = chat_llm.invoke(state[\"messages\"])  # AIMessage\n",
        "    return {\n",
        "        \"messages\": [response]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac4ec08",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "3508bf54",
      "metadata": {},
      "outputs": [],
      "source": [
        "def token_counter(state: GraphState) -> dict:\n",
        "    \"\"\"Count tokens (simple word count) in the last AI message.\"\"\"\n",
        "    last_msg = state[\"messages\"][-1]\n",
        "    content = last_msg.content\n",
        "    # AIMessage.content can be str or list of blocks (e.g. multimodal/tool calls)\n",
        "    if isinstance(content, list):\n",
        "        text = \" \".join(\n",
        "            (c.get(\"text\", c) if isinstance(c, dict) else str(c)) for c in content\n",
        "        )\n",
        "    else:\n",
        "        text = content or \"\"\n",
        "    token_number = len(text.split())\n",
        "    summary = f\"Total token number in the generated answer (word count) is {token_number}\"\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=summary)]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "c0e0b543",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "66213d5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = StateGraph(GraphState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "d2079498",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11ec1c850>"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "builder.add_node(\"llm_call\", llm_call)\n",
        "builder.add_node(\"token_counter\", token_counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "39266b6b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11ec1c850>"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "builder.set_entry_point(\"llm_call\")\n",
        "builder.add_edge(\"llm_call\", \"token_counter\")\n",
        "builder.set_finish_point(\"token_counter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346919d8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f25d489",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "34e542b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "app = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "febea80a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=RunnableCallable(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'llm_call': Node(id='llm_call', name='llm_call', data=llm_call(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'token_counter': Node(id='token_counter', name='token_counter', data=token_counter(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=None, metadata=None)}, edges=[Edge(source='__start__', target='llm_call', data=None, conditional=False), Edge(source='llm_call', target='token_counter', data=None, conditional=False), Edge(source='token_counter', target='__end__', data=None, conditional=False)])"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.get_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "e38d3e0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "id": "55e43582",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27b697f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = app.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Hi, this is Sunny. Say hello in detail.\")]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e84efaaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
